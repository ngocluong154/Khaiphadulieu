{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-08T14:25:38.424557Z","iopub.execute_input":"2022-04-08T14:25:38.425235Z","iopub.status.idle":"2022-04-08T14:25:38.438706Z","shell.execute_reply.started":"2022-04-08T14:25:38.425163Z","shell.execute_reply":"2022-04-08T14:25:38.438019Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/adaboostlet/letters_CG.txt',sep=' ')\nonlydata=data.loc[:,'x-box':'yegvx']\nonlydata.describe(include='all')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-08T14:25:38.440187Z","iopub.execute_input":"2022-04-08T14:25:38.440905Z","iopub.status.idle":"2022-04-08T14:25:38.525542Z","shell.execute_reply.started":"2022-04-08T14:25:38.440870Z","shell.execute_reply":"2022-04-08T14:25:38.524478Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nX=onlydata.values\nyCG=data.values[:,0]\ny=np.zeros((yCG.size))\ny[yCG=='G']=1\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 0)\n# Standardize the x_train and x_test datasets\nstd_scaler = preprocessing.StandardScaler().fit(X_train)\nX_train_scaled = std_scaler.transform(X_train)\nX_test_scaled = std_scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T14:25:38.527606Z","iopub.execute_input":"2022-04-08T14:25:38.527977Z","iopub.status.idle":"2022-04-08T14:25:39.622041Z","shell.execute_reply.started":"2022-04-08T14:25:38.527910Z","shell.execute_reply":"2022-04-08T14:25:39.621167Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\npca = PCA(n_components=2)\nfig, (plttrain, plttest) = plt.subplots(1, 2)\ndatavl1=pca.fit_transform(X_train_scaled)\ng11=datavl1[(y_train==1)]\ng12=datavl1[(y_train==0)]\nplttrain.set_title('Train values :'+ str(X_train_scaled.shape))\nplttrain.scatter(g11[:,0],g11[:,1],marker='o')\nplttrain.scatter(g12[:,0],g12[:,1],marker='+')\nplttrain.legend(['lable 1','lable 0'])\ndatavl2=pca.fit_transform(X_test_scaled)\ng21=datavl2[(y_test==1)]\ng22=datavl2[(y_test==0)]\nplttest.set_title('Test values :'+str(X_test_scaled.shape))\nplttest.scatter(g21[:,0],g21[:,1],marker='o')\nplttest.scatter(g22[:,0],g22[:,1],marker='+')\nplttest.legend(['lable 1','lable 0'])\nplt.savefig('lettersCG_Xtraintext.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T14:25:39.623421Z","iopub.execute_input":"2022-04-08T14:25:39.623725Z","iopub.status.idle":"2022-04-08T14:25:40.367292Z","shell.execute_reply.started":"2022-04-08T14:25:39.623686Z","shell.execute_reply":"2022-04-08T14:25:40.366481Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"pca= PCA(n_components=2)\n# fig, (plttrain, plttest) = plt.subplots(1, 2)\ndatavlx=pca.fit_transform(X)\ngx1=datavlx[(y==1)]\ngx2=datavlx[(y==0)]\nplt.title('Train values :'+ str(X.shape))\nplt.scatter(gx1[:,0],gx1[:,1],marker='o')\nplt.scatter(gx2[:,0],gx2[:,1],marker='+')\nplt.legend(['lable 1','lable 0'])\nplt.savefig('lettersCG_X.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T14:25:40.369668Z","iopub.execute_input":"2022-04-08T14:25:40.370013Z","iopub.status.idle":"2022-04-08T14:25:40.799702Z","shell.execute_reply.started":"2022-04-08T14:25:40.369968Z","shell.execute_reply":"2022-04-08T14:25:40.798867Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class RatingModel:\n    def __init__(self, y_, y_Pr):\n      self.y_=y_\n      self.y_Pr=y_Pr\n      self.TN=np.size(y_Pr[(y_Pr==-1)&(y_==y_Pr)])\n      self.FN=np.size(y_Pr[(y_Pr==-1)&(y_!=y_Pr)])\n      self.TP=np.size(y_Pr[(y_Pr==1)&(y_==y_Pr)])\n      self.FP=np.size(y_Pr[(y_Pr==1)&(y_!=y_Pr)])\n      self.y_[self.y_==0]=-1\n      self.y_Pr[self.y_Pr==0]=-1\n      # assert self.y_.set={1, -1}\n      # assert self.y_Pr.set={1, -1}\n    def __rep__():\n        return \"\"\n    def accur_Error(self, y_, y_Pr):\n        rs=(self.TP+self.TN)/(y_.size)\n        return [rs,(1-rs)]\n    def sensitivity(self):\n        P=np.size(self.y_[self.y_==1])\n        return (self.TP)/(P)\n    def specificity(self):\n        N=np.size(self.y_[self.y_==-1])\n        return (self.TN)/(N)\n    def precision(self):\n        rs=self.TP+self.FP\n        return (self.TP)/(rs)\n    def recall(self):\n        rs=self.TP+self.FN\n        return (self.TP)/(rs)\n    def rating(self):\n        return [self.accur_Error(self.y_, self.y_Pr), self.sensitivity(), self.specificity(), self.precision(), self.recall()]\nclass DecisionStump:\n    def __init__(self, T=100):\n        self.T = T\n        pass\n\n    def fit(self, X: np.ndarray, y: np.ndarray, sample_weight: np.ndarray):\n        T = self.T\n        W=sample_weight\n        nrow, ncol = X.shape\n        assert nrow == y.size\n\n        bestn = 0\n        bestd = 1\n        bestp = 0\n        minerr = W.sum()\n        for i in range(ncol):\n            err, d, p = self._optimize(X[:, i], y, W, T)\n            if err < minerr:\n                minerr = err\n                bestn = i\n                bestd = d\n                bestp = p\n        \n        self.features = ncol\n        self.bestn = bestn\n        self.bestd = bestd\n        self.bestp = bestp\n\n        return self\n\n    def _optimize(self, X, y, W, T):\n        X = X.flatten()\n        min_x, max_x = X.min(), X.max()\n        len_x = max_x - min_x\n        \n        bestd = 1\n        bestp = min_x\n        minerr = W.sum()\n\n        if len_x > 0.0:\n            for p in np.arange(min_x, max_x, len_x/T):\n                for d in [-1, 1]:\n                    gy = np.ones((y.size))\n                    gy[X*d < p*d] = -1\n                    err = np.sum((gy != y)*W)\n                    if err < minerr:\n                        minerr = err\n                        bestd = d\n                        bestp = p\n\n        return minerr, bestd, bestp\n\n    def predict(self, test_set : np.ndarray):\n        nrow, ncol = test_set.shape\n\n        assert ncol == self.features\n\n        icol = test_set[:, self.bestn]\n        h = np.ones((nrow))\n        h[icol*self.bestd < self.bestp*self.bestd] = -1\n        return h\nclass AdaBoost:\n    def __init__(self , T, hmodel = DecisionStump()):\n        self.T=T\n        self.hmodel=hmodel\n    def fit(self, X: np.ndarray, y_: np.ndarray, verbose=False):\n      n = X.shape[0]\n      T = self.T\n      y=y_\n      y[y==0]=-1\n    # init numpy arrays\n      self.D = np.zeros(shape=(T, n))\n      self.h = np.zeros(shape=T, dtype=object)\n      self.alpha = np.zeros(shape=T)\n      self.errors = np.zeros(shape=T)\n      self.ratting = np.zeros(shape=(T,2))\n\n      # initialize weights uniformly\n      self.D[0] = np.ones(shape=n) / n\n\n      for t in range(T):\n          # fit  weak learner\n          D_ = self.D[t]\n          h_ = DecisionStump(60)\n          h_ = h_.fit(X, y, D_)\n\n          # calculate error and stump weight from weak learner prediction\n          Pr_ = h_.predict(X)\n          error_ = D_[(Pr_ != y)].sum()# / n\n          alpha_ = np.log((1 - error_) / error_) / 2\n\n          # update sample weights\n          D_new = (\n              D_ * np.exp(-alpha_ * y * Pr_)\n          )\n          \n          D_new /= D_new.sum()\n\n          # If not final iteration, update sample weights for t+1\n          if t+1 < T:\n              self.D[t+1] = D_new\n\n          # save results of iteration\n          self.h[t] = h_\n          self.alpha[t] = alpha_\n          self.errors[t] = error_\n          # ae=np.array([0,0])\n          if t>0:\n            Pr_temp=self.predictmodul(X,t)\n            modelra=RatingModel(y, Pr_temp)\n            self.ratting[t,:]=modelra.accur_Error(y, Pr_temp)\n          if verbose: print('Training {0}-th weak classifier: accuracy={1}, error={2}'.format (t, self.ratting[t,0], self.ratting[t,1]))\n      return self\n    def predict(self, X):\n        Pr_ = np.array([h_.predict(X) for h_ in self.h])\n        return np.sign(np.dot(self.alpha, Pr_))\n    def predictmodul(self, X, i):\n        h_temp=self.h[:i]\n        alpha_temp=self.alpha[:i]\n        Pr_ = np.array([h_.predict(X) for h_ in h_temp])\n        return np.sign(np.dot(alpha_temp, Pr_))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T14:25:40.800964Z","iopub.execute_input":"2022-04-08T14:25:40.801194Z","iopub.status.idle":"2022-04-08T14:25:40.839409Z","shell.execute_reply.started":"2022-04-08T14:25:40.801166Z","shell.execute_reply":"2022-04-08T14:25:40.838605Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model=AdaBoost(60)\nmodel=model.fit(X_train_scaled, y_train,  True )\nPr=model.predict( X_test_scaled)\nPr[(Pr==0)]=-1\n# print(Pr, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T14:25:40.841065Z","iopub.execute_input":"2022-04-08T14:25:40.841363Z","iopub.status.idle":"2022-04-08T14:25:47.020964Z","shell.execute_reply.started":"2022-04-08T14:25:40.841275Z","shell.execute_reply":"2022-04-08T14:25:47.019984Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ra_Xtest = np.zeros(shape=(model.T,2))\nfor i in range(1,model.T):\n  Pr_i=model.predictmodul(X_test_scaled,i)\n  modelra=RatingModel(y_test, Pr_i)\n  ra_Xtest[i,:]=modelra.accur_Error(y_test, Pr_i)\nra_Xtrain = np.zeros(shape=(model.T,2))\nfor i in range(1,model.T):\n  Pr_i=model.predictmodul(X_train_scaled,i)\n  modelra=RatingModel(y_train, Pr_i)\n  ra_Xtrain[i,:]=modelra.accur_Error(y_train, Pr_i)\niter=range(model.T)\nplt.plot(iter,ra_Xtest[:,0],'g-', label='Test accuracy')\nplt.plot(iter,ra_Xtest[:,1],'r-', label='Test error')\nplt.plot(iter,ra_Xtrain[:,0],'g--', label='Train accuracy')\nplt.plot(iter,ra_Xtrain[:,1],'r--', label='Train error')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-08T14:25:47.026520Z","iopub.execute_input":"2022-04-08T14:25:47.027503Z","iopub.status.idle":"2022-04-08T14:25:47.392870Z","shell.execute_reply.started":"2022-04-08T14:25:47.027446Z","shell.execute_reply":"2022-04-08T14:25:47.391993Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"sumerror=0;\ny_new=y_test\ny_new[y_new==0]=-1\n# for i in range(y_new.shape[0]):\n#   if y_new[i]!=Pr[i]: \n#     sumerror+=1\nsumerror=np.size(y_new[Pr!=y_new])\ngT1=datavl2[(Pr==1)]\ngT0=datavl2[(Pr==-1)]\ngF1=datavl2[(y_new!=Pr)&(Pr==1)]\ngF0=datavl2[(y_new!=Pr)&(Pr==-1)]\nplt.title('Test values errors :'+str(sumerror)+'/ '+str(X_test_scaled.shape[0]))\nplt.scatter(gT1[:,0],gT1[:,1], marker='o')\nplt.scatter(gT0[:,0],gT0[:,1], marker='+')\nplt.scatter(gF1[:,0],gF1[:,1], c=\"red\", marker='o')\nplt.scatter(gF0[:,0],gF0[:,1], c=\"red\", marker='+')\nplt.legend(['Predict true 1', 'Predict true 0', 'Predict false'])\nplt.savefig('lettersCG_XtextError.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T14:25:47.394041Z","iopub.execute_input":"2022-04-08T14:25:47.394247Z","iopub.status.idle":"2022-04-08T14:25:47.700641Z","shell.execute_reply.started":"2022-04-08T14:25:47.394212Z","shell.execute_reply":"2022-04-08T14:25:47.699688Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}